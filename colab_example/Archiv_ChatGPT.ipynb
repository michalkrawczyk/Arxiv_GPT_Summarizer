{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OJ3k4aYlKWsa",
        "63IjeiX99pzO",
        "Yc14x1cEpeA_",
        "WIhlY_tRqOcn",
        "Hle6_Mbmrnk-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "h7AMvdMkRUW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/michalkrawczyk/Arxiv_GPT_Summarizer.git\n",
        "%cd Arxiv_GPT_Summarizer\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Libraries Installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqvql9x88dQn",
        "outputId": "2d22c092-8a82-489c-bb4e-186f1020c16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries Installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from arxiv_utils import download_paper_from_arxiv, download_recent_papers_by_querry, PaperData\n",
        "from gpt_core import get_description_json, get_summary, PROMPTS, reload_prompts\n",
        "from datasets import PaperDataset\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import os\n",
        "from shutil import move\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "UNaahvK7-o4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Files to summary (Choose option)"
      ],
      "metadata": {
        "id": "pvm7IWuyA7Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Specify settings for downloading papers by search querry\n",
        "#@markdown ---\n",
        "#@markdown Note: This will download most recent papers found with querry\n",
        "SEARCH_QUERRY = \"Artificial Inteligence\" #@param {type:\"string\"}\n",
        "assert SEARCH_QUERRY, \"Empty search quarry\"\n",
        "#@markdown ---\n",
        "#@markdown Number of papers to download\n",
        "#@markdown ---\n",
        "\n",
        "NUMBER_OF_PAPERS = 3 #@param {type:\"integer\"}\n",
        "assert NUMBER_OF_PAPERS > 0\n",
        "#@markdown <br>\n",
        "\n",
        "DOWNLOADED_PAPERS = download_recent_papers_by_querry(SEARCH_QUERRY, NUMBER_OF_PAPERS)\n",
        "print(\"\\nDownloaded papers:\")\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  print(f\"\\t{p}\")\n",
        "SEARCH_TYPE = \"QUERRY\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U4V6CTiRBCJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9db37f-c296-4c18-8b22-d5aa51fbffe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading files...: 3it [00:03,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloaded papers:\n",
            "\t./2305.08854v1.Laughing_Matters__Introducing_Laughing_Face_Generation_using_Diffusion_Models.pdf\n",
            "\t./2305.08852v1.Python_Tool_for_Visualizing_Variability_of_Pareto_Fronts_over_Multiple_Runs.pdf\n",
            "\t./2305.08848v1.Small_Models_are_Valuable_Plug_ins_for_Large_Language_Models.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>or</b></h3>"
      ],
      "metadata": {
        "id": "RhoJp1NzB-ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Provide papers to download by Arxiv ID\n",
        "#@markdown ---\n",
        "#@markdown Each paper id must be separated by space (' ') or comma (',')\n",
        "PAPERS_BY_ID = \"2301.05586, 2305.04889\" #@param {type:\"string\"}\n",
        "\n",
        "PAPERS_BY_ID = PAPERS_BY_ID.replace(' ', ',').split(',')\n",
        "PAPERS_BY_ID = [p for p in PAPERS_BY_ID if p]\n",
        "DOWNLOADED_PAPERS = download_paper_from_arxiv(PAPERS_BY_ID)\n",
        "print(\"\\nDownloaded papers:\")\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  print(f\"\\t{p}\")\n",
        "\n",
        "SEARCH_TYPE = \"ID\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Wa3SQ7J8B_Pw",
        "outputId": "2d57d57a-4d4b-4a3b-deb1-871468f13d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading files...: 2it [00:09,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloaded papers:\n",
            "\t./2301.05586v1.YOLOv6_v3_0_A_Full_Scale_Reloading.pdf\n",
            "\t./2305.04889v1.Improving_Real_Time_Bidding_in_Online_Advertising_Using_Markov_Decision_Processes_and_Machine_Learning_Techniques.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Examples"
      ],
      "metadata": {
        "id": "IbI0Zee9Redg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single file example usage"
      ],
      "metadata": {
        "id": "OJ3k4aYlKWsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_paper_from_arxiv([\"2301.05586v1\"])"
      ],
      "metadata": {
        "id": "oyFkjNGoKyr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper = PaperData(\"./2301.05586v1.YOLOv6_v3_0_A_Full_Scale_Reloading.pdf\")\n",
        "get_description_json(paper)"
      ],
      "metadata": {
        "id": "DuFiWVu2HT4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper = PaperData(\"./2301.05586v1.YOLOv6_v3_0_A_Full_Scale_Reloading.pdf\")\n",
        "summary = get_summary_3(paper)\n",
        "print(summary[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpQKiQeT15x9",
        "outputId": "5d3b3b0c-02ad-4438-9632-18737a382ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [04:20<00:00, 52.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Features:\n",
            "- YOLOv6 v3.0 has numerous novel enhancements on the network architecture and the training scheme.\n",
            "- The neck of the detector is renewed with a Bi-directional Concatenation (BiC) module to provide more accurate localization signals.\n",
            "- Anchor-aided training (AAT) strategy is proposed to enjoy the advantages of both anchor-based and anchor-free paradigms without touching inference efficiency.\n",
            "- YOLOv6 is deepened to have another stage in the backbone and the neck, which reinforces it to hit a new state-of-the-art performance on the COCO dataset at a high-resolution input.\n",
            "- A new self-distillation strategy is involved to boost the performance of small models of YOLOv6.\n",
            "\n",
            "New Strategies:\n",
            "- Anchor-aided training (AAT) strategy is proposed to enjoy the advantages of both anchor-based and anchor-free paradigms without touching inference efficiency.\n",
            "- A new self-distillation strategy is involved to boost the performance of small models of YOLOv6.\n",
            "\n",
            "Problems:\n",
            "- The YOLO community has been in high spirits since the first two releases.\n",
            "- YOLOv4 reorganized the detection framework into several separate parts (backbone, neck and head), and verified bag-of-freebies and bag-of-specials at the time to design a framework suitable for training on a single GPU.\n",
            "- At present, YOLOv5, YOLOX, PPYOLOE, YOLOv7 and most recently YOLOv8 are all the competing candidates for efficient detectors to deploy.\n",
            "\n",
            "Design:\n",
            "- YOLOv6 has an enhanced-PAN as its detection neck, which is designed to augment localization signals without bringing in excessive computation burden.\n",
            "- A Bi-directional Concatenation (BiC) module is proposed to integrate feature maps of three adjacent layers, which fuses an extra low-level feature from backbone Ci-1 into Pi.\n",
            "- The neck of YOLOv6 is denoted as RepBi-PAN.\n",
            "\n",
            "Results:\n",
            "- YOLOv6-N hits 37.5% AP on the COCO dataset at a throughput of 1187 FPS tested with an NVIDIA Tesla T4 GPU.\n",
            "- YOLOv6-S strikes 45.0% AP at 484 FPS, outperforming other mainstream detectors at the same scale.\n",
            "- YOLOv6-M/L achieve better accuracy performance (50.0%/52.8% respectively) than other detectors at a similar inference speed.\n",
            "- With an extended backbone and neck design, YOLOv6-L6 achieves the state-of-the-art accuracy in real-time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make List with short Summaries"
      ],
      "metadata": {
        "id": "dt6tJLRU_ao1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PaperDataset()\n",
        "if SEARCH_TYPE == \"QUERRY\":\n",
        "  dataset.search_and_add_papers(SEARCH_QUERRY, NUMBER_OF_PAPERS)\n",
        "  # dataset.search_and_add_papers(\"Artificial Inteligence\", 3)\n",
        "else:\n",
        "  dataset.add_papers_by_id(PAPERS_BY_ID)\n",
        "\n",
        "print()\n",
        "print(\"Dataset Papers:\", dataset.list_of_papers)\n",
        "print(\"Dataset Features:\", dataset.list_data_fields)\n",
        "print(\"Dataset New Features:\", dataset.list_new_features)\n",
        "print(\"Dataset Paper Categories:\", dataset.list_values_by_field(\"Model Category\"))\n",
        "print()\n",
        "\n",
        "# Filter valuable papers by keywoard\n",
        "summaries = dataset.search_by_field_value(\"New Features\", \"Novel\")"
      ],
      "metadata": {
        "id": "EGgGFCSY8aoy",
        "outputId": "0afccb6f-3c5b-41b5-b9dd-30e45aeb0ef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading files...: 3it [00:00,  9.93it/s]\n",
            "Updating list of papers: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Papers: dict_keys(['2305.08854v1.Laughing_Matters__Introducing_Laughing_Face_Generation_using_Diffusion_Models.pdf', '2305.08852v1.Python_Tool_for_Visualizing_Variability_of_Pareto_Fronts_over_Multiple_Runs.pdf', '2305.08848v1.Small_Models_are_Valuable_Plug_ins_for_Large_Language_Models.pdf'])\n",
            "Dataset Features: ['Model Name', 'New Features', 'Year', 'Model Category', 'filepath', 'SOTA']\n",
            "Dataset New Features: {'Novel model capable of generating realistic laughter sequences', 'Python package for empirical attainment surface visualization', 'Allows black-box LLMs to work with locally fine-tuned smaller models resulting in improved performance on supervised tasks. Enhances the capabilities of smaller models such as multilinguality and interpretability.'}\n",
            "Dataset Paper Categories: {'NLP', 'Image Generation', 'unknown'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save short summaries in json file\n",
        "with open(\"short_summary.json\", 'w') as f:\n",
        "  json.dump(summaries, f, indent=2)"
      ],
      "metadata": {
        "id": "mddqtd5RC5T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Packages with longer summary"
      ],
      "metadata": {
        "id": "63IjeiX99pzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for p in tqdm(DOWNLOADED_PAPERS[:1]):\n",
        "  try:\n",
        "    paper = PaperData(p)\n",
        "    summary = get_summary(paper)\n",
        "\n",
        "    paper_dir = os.path.splitext(os.path.basename(p))[0].split('.')[-1]\n",
        "    if not os.path.isdir(paper_dir):\n",
        "      os.makedirs(paper_dir)\n",
        "    \n",
        "    move(p, f\"{paper_dir}/{os.path.basename(p)}\")\n",
        "    with open(f\"{paper_dir}/summary.txt\", 'w') as f:\n",
        "      f.write(summary[-1])\n",
        "      \n",
        "  except Exception as err:\n",
        "    print(f\"\"\"Failed to summarize: {p}\n",
        "            - {err}\"\"\")\n"
      ],
      "metadata": {
        "id": "qqA-cWeL9plK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in DOWNLOADED_PAPERS:\n",
        "  paper_directory = os.path.splitext(os.path.basename(p))[0].split('.')[-1]\n",
        "  if os.path.isdir(paper_directory):\n",
        "    # Shell commands sometimes don't work with 'f\" '\n",
        "    zipname = paper_directory + \".zip\"\n",
        "    !zip -rm $zipname $paper_directory "
      ],
      "metadata": {
        "id": "jdx-LrzBl_gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Save Paper and summary in Google Drive or download"
      ],
      "metadata": {
        "id": "kIoOvM4RpPQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download"
      ],
      "metadata": {
        "id": "Yc14x1cEpeA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  zipfile = os.path.splitext(os.path.basename(p))[0].split('.')[-1] + \".zip\"\n",
        "\n",
        "  if os.path.isfile(zipfile):\n",
        "    files.download(zipfile) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CyVV6iuPpnIB",
        "outputId": "6aa1061f-c3db-4fe4-9bbe-7226d85ad4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c76e7f9-232e-417f-b85c-c4f3e92e1534\", \"YOLOv6_v3_0_A_Full_Scale_Reloading.zip\", 561420)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Move to Google drive"
      ],
      "metadata": {
        "id": "WIhlY_tRqOcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "GOOGLE_DRIVE_OUTPUT_DIRECTORY = \"/content/drive/MyDrive/\"\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  zipfile = os.path.splitext(os.path.basename(p))[0].split('.')[-1] + \".zip\"\n",
        "\n",
        "  if os.path.isfile(zipfile):\n",
        "    move(zipfile, os.path.join(GOOGLE_DRIVE_OUTPUT_DIRECTORY, zipfile))\n",
        "    print(f\"Moved {zipfile} to {GOOGLE_DRIVE_OUTPUT_DIRECTORY}\")"
      ],
      "metadata": {
        "id": "-xgjIFSTqRH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Download short summary"
      ],
      "metadata": {
        "id": "Hle6_Mbmrnk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"short_summary.json\") "
      ],
      "metadata": {
        "id": "Iz4wGUQCrrRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}