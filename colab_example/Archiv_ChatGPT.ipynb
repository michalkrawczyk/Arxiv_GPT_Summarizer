{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OJ3k4aYlKWsa",
        "63IjeiX99pzO",
        "Yc14x1cEpeA_",
        "WIhlY_tRqOcn",
        "Hle6_Mbmrnk-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "h7AMvdMkRUW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/michalkrawczyk/Arxiv_GPT_Summarizer.git\n",
        "%cd Arxiv_GPT_Summarizer\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Libraries Installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqvql9x88dQn",
        "outputId": "18f28c20-f7d2-404e-d8b9-3803f2a6865d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries Installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from arxiv_utils import download_paper_from_arxiv, download_recent_papers_by_querry, PaperData\n",
        "from gpt_core import get_description_json, get_summary, PROMPTS, reload_prompts\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import os\n",
        "from shutil import move\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "UNaahvK7-o4I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Files to summary (Choose option)"
      ],
      "metadata": {
        "id": "pvm7IWuyA7Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Specify settings for downloading papers by search querry\n",
        "#@markdown ---\n",
        "#@markdown Note: This will download most recent papers found with querry\n",
        "SEARCH_QUERRY = \"Artificial Inteligence\" #@param {type:\"string\"}\n",
        "assert SEARCH_QUERRY, \"Empty search quarry\"\n",
        "#@markdown ---\n",
        "#@markdown Number of papers to download\n",
        "#@markdown ---\n",
        "\n",
        "NUMBER_OF_PAPERS = 3 #@param {type:\"integer\"}\n",
        "assert NUMBER_OF_PAPERS > 0\n",
        "#@markdown <br>\n",
        "\n",
        "DOWNLOADED_PAPERS = download_recent_papers_by_querry(SEARCH_QUERRY, NUMBER_OF_PAPERS)\n",
        "print(\"\\nDownloaded papers:\")\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  print(f\"\\t{p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "U4V6CTiRBCJp",
        "outputId": "4c3123e9-e950-4f44-8dc8-164379ec3093"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading files...: 3it [00:19,  6.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloaded papers:\n",
            "\t./2305.06349v1.RECKONING_Reasoning_through_Dynamic_Knowledge_Encoding.pdf\n",
            "\t./2305.06324v1.Alternating_Gradient_Descent_and_Mixture_of_Experts_for_Integrated_Multimodal_Perception.pdf\n",
            "\t./2305.06314v1.Scan2LoD3_Reconstructing_semantic_3D_building_models_at_LoD3_using_ray_casting_and_Bayesian_networks.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>or</b></h3>"
      ],
      "metadata": {
        "id": "RhoJp1NzB-ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Provide papers to download by Arxiv ID\n",
        "#@markdown ---\n",
        "#@markdown Each paper id must be separated by space (' ') or comma (',')\n",
        "PAPERS_BY_ID = \"2301.05586, 2305.04889\" #@param {type:\"string\"}\n",
        "\n",
        "PAPERS_BY_ID = PAPERS_BY_ID.replace(' ', ',').split(',')\n",
        "PAPERS_BY_ID = [p for p in PAPERS_BY_ID if p]\n",
        "DOWNLOADED_PAPERS = download_paper_from_arxiv(PAPERS_BY_ID)\n",
        "print(\"\\nDownloaded papers:\")\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  print(f\"\\t{p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Wa3SQ7J8B_Pw",
        "outputId": "2d57d57a-4d4b-4a3b-deb1-871468f13d85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading files...: 2it [00:09,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloaded papers:\n",
            "\t./2301.05586v1.YOLOv6_v3_0_A_Full_Scale_Reloading.pdf\n",
            "\t./2305.04889v1.Improving_Real_Time_Bidding_in_Online_Advertising_Using_Markov_Decision_Processes_and_Machine_Learning_Techniques.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Examples"
      ],
      "metadata": {
        "id": "IbI0Zee9Redg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single file example usage"
      ],
      "metadata": {
        "id": "OJ3k4aYlKWsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_paper_from_arxiv([\"2301.05586v1\"])"
      ],
      "metadata": {
        "id": "oyFkjNGoKyr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper = PaperData(\"./2301.05586v1.YOLOv6_v3_0_A_Full_Scale_Reloading.pdf\")\n",
        "get_description_json(paper)"
      ],
      "metadata": {
        "id": "DuFiWVu2HT4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper = PaperData(\"./2301.05586v1.YOLOv6_v3_0_A_Full_Scale_Reloading.pdf\")\n",
        "summary = get_summary_3(paper)\n",
        "print(summary[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpQKiQeT15x9",
        "outputId": "5d3b3b0c-02ad-4438-9632-18737a382ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [04:20<00:00, 52.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Features:\n",
            "- YOLOv6 v3.0 has numerous novel enhancements on the network architecture and the training scheme.\n",
            "- The neck of the detector is renewed with a Bi-directional Concatenation (BiC) module to provide more accurate localization signals.\n",
            "- Anchor-aided training (AAT) strategy is proposed to enjoy the advantages of both anchor-based and anchor-free paradigms without touching inference efficiency.\n",
            "- YOLOv6 is deepened to have another stage in the backbone and the neck, which reinforces it to hit a new state-of-the-art performance on the COCO dataset at a high-resolution input.\n",
            "- A new self-distillation strategy is involved to boost the performance of small models of YOLOv6.\n",
            "\n",
            "New Strategies:\n",
            "- Anchor-aided training (AAT) strategy is proposed to enjoy the advantages of both anchor-based and anchor-free paradigms without touching inference efficiency.\n",
            "- A new self-distillation strategy is involved to boost the performance of small models of YOLOv6.\n",
            "\n",
            "Problems:\n",
            "- The YOLO community has been in high spirits since the first two releases.\n",
            "- YOLOv4 reorganized the detection framework into several separate parts (backbone, neck and head), and verified bag-of-freebies and bag-of-specials at the time to design a framework suitable for training on a single GPU.\n",
            "- At present, YOLOv5, YOLOX, PPYOLOE, YOLOv7 and most recently YOLOv8 are all the competing candidates for efficient detectors to deploy.\n",
            "\n",
            "Design:\n",
            "- YOLOv6 has an enhanced-PAN as its detection neck, which is designed to augment localization signals without bringing in excessive computation burden.\n",
            "- A Bi-directional Concatenation (BiC) module is proposed to integrate feature maps of three adjacent layers, which fuses an extra low-level feature from backbone Ci-1 into Pi.\n",
            "- The neck of YOLOv6 is denoted as RepBi-PAN.\n",
            "\n",
            "Results:\n",
            "- YOLOv6-N hits 37.5% AP on the COCO dataset at a throughput of 1187 FPS tested with an NVIDIA Tesla T4 GPU.\n",
            "- YOLOv6-S strikes 45.0% AP at 484 FPS, outperforming other mainstream detectors at the same scale.\n",
            "- YOLOv6-M/L achieve better accuracy performance (50.0%/52.8% respectively) than other detectors at a similar inference speed.\n",
            "- With an extended backbone and neck design, YOLOv6-L6 achieves the state-of-the-art accuracy in real-time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make List with short Summaries"
      ],
      "metadata": {
        "id": "dt6tJLRU_ao1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = []\n",
        "\n",
        "for p in tqdm(DOWNLOADED_PAPERS):\n",
        "  try:\n",
        "    # make summary for each paper\n",
        "    paper = PaperData(p)\n",
        "    desc = get_description_json(paper, 1300)\n",
        "    desc[\"filename\"] = os.path.basename(p)\n",
        "    summaries.append(desc)\n",
        "  \n",
        "  except Exception as err:\n",
        "    print(f\"\"\"Failed to summarize: {p}\n",
        "            - {err}\"\"\")"
      ],
      "metadata": {
        "id": "EGgGFCSY8aoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save short summaries in json file\n",
        "with open(\"short_summary.json\", 'w') as f:\n",
        "  json.dump(summaries, f, indent=2)"
      ],
      "metadata": {
        "id": "mddqtd5RC5T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Packages with longer summary"
      ],
      "metadata": {
        "id": "63IjeiX99pzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for p in tqdm(DOWNLOADED_PAPERS[:1]):\n",
        "  try:\n",
        "    paper = PaperData(p)\n",
        "    summary = get_summary(paper)\n",
        "\n",
        "    paper_dir = os.path.splitext(os.path.basename(p))[0].split('.')[-1]\n",
        "    if not os.path.isdir(paper_dir):\n",
        "      os.makedirs(paper_dir)\n",
        "    \n",
        "    move(p, f\"{paper_dir}/{os.path.basename(p)}\")\n",
        "    with open(f\"{paper_dir}/summary.txt\", 'w') as f:\n",
        "      f.write(summary[-1])\n",
        "      \n",
        "  except Exception as err:\n",
        "    print(f\"\"\"Failed to summarize: {p}\n",
        "            - {err}\"\"\")\n"
      ],
      "metadata": {
        "id": "qqA-cWeL9plK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in DOWNLOADED_PAPERS:\n",
        "  paper_directory = os.path.splitext(os.path.basename(p))[0].split('.')[-1]\n",
        "  if os.path.isdir(paper_directory):\n",
        "    # Shell commands sometimes don't work with 'f\" '\n",
        "    zipname = paper_directory + \".zip\"\n",
        "    !zip -rm $zipname $paper_directory "
      ],
      "metadata": {
        "id": "jdx-LrzBl_gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Save Paper and summary in Google Drive or download"
      ],
      "metadata": {
        "id": "kIoOvM4RpPQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download"
      ],
      "metadata": {
        "id": "Yc14x1cEpeA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  zipfile = os.path.splitext(os.path.basename(p))[0].split('.')[-1] + \".zip\"\n",
        "\n",
        "  if os.path.isfile(zipfile):\n",
        "    files.download(zipfile) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CyVV6iuPpnIB",
        "outputId": "6aa1061f-c3db-4fe4-9bbe-7226d85ad4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c76e7f9-232e-417f-b85c-c4f3e92e1534\", \"YOLOv6_v3_0_A_Full_Scale_Reloading.zip\", 561420)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Move to Google drive"
      ],
      "metadata": {
        "id": "WIhlY_tRqOcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "GOOGLE_DRIVE_OUTPUT_DIRECTORY = \"/content/drive/MyDrive/\"\n",
        "for p in DOWNLOADED_PAPERS:\n",
        "  zipfile = os.path.splitext(os.path.basename(p))[0].split('.')[-1] + \".zip\"\n",
        "\n",
        "  if os.path.isfile(zipfile):\n",
        "    move(zipfile, os.path.join(GOOGLE_DRIVE_OUTPUT_DIRECTORY, zipfile))\n",
        "    print(f\"Moved {zipfile} to {GOOGLE_DRIVE_OUTPUT_DIRECTORY}\")"
      ],
      "metadata": {
        "id": "-xgjIFSTqRH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Download short summary"
      ],
      "metadata": {
        "id": "Hle6_Mbmrnk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"short_summary.json\") "
      ],
      "metadata": {
        "id": "Iz4wGUQCrrRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}